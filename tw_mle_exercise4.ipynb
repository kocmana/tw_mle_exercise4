{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# MLE - Exercise 2 - Comparative Experimentation\n",
    "## Andreas Kocman (se19m024)\n",
    "\n",
    "## Assignment\n",
    "This exercise follows very much the style of the previous exercise - you shall do experiments with different data sets and classifiers. Again, you can do the exercise alone, or in a group of two.\n",
    "\n",
    "The datasets to use are\n",
    "* The datasets from the exercise 3, i.e. Iris, Optical Digits (and if you are in a group, then also Breast Cancer)\n",
    "* Either the music or the image data set - decided by your matriculation number modulo 2, 0 means music, 1 means image (If you are doing this exercise in a group, then you shall take both data sets)\n",
    "\n",
    "The classifiers & parameters to use are\n",
    "* All the classifiers & parameters from exercise 3\n",
    "* Decision trees, you shall have two setups: one fully grown tree, and one setting for a pruned or pre-pruned tree.\n",
    "   * (If you are a group, you shall try a total of four settings: two unpruned trees using two different split criteria, and two setups for different amounts of (pre)-pruning the tree.)\n",
    "* Random Forests, using two different settings for the number of trees\n",
    "   * (If you are in a group, also vary the number of attributes that are used in each split; use three different values resp. computation methods (sqrt, log, fraction, ...); this should give you a total of 6 runs: (2 number of trees) x (3 number of attributes))\n",
    "* SVMs: just use the default settings, but use both SVC and LinearSVC classifiers (http://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html, http://scikit-learn.org/stable/modules/generated/sklearn.svm.LinearSVC.html)\n",
    "\n",
    "### Image Dataset\n",
    "We will use the \"Fruit Image Dataset\", originally provided at http://data.vicos.si/datasets/FIDS30/, but with an edited version linked from Moodle (some images had an encoding not compatible with e.g. python libraries). Your task is to classify images into the category of fruit (a total of 30 defined categories) they belong to.\n",
    "\n",
    "As this is image data, feature extraction is a requirement before we can actually learn anything. As you shouldn't spend too much time on that, there is demo code on how to work with this data available, linked from the course main page.\n",
    "\n",
    "This code generates a set of 4 different features, all rather simple and based on histograms of colours (i.e. counts on how often a certain colour appears). You shall work with all four of them, and likely will see very different results.\n",
    "\n",
    "### Music Dataset\n",
    "We will use the dataset provided by George Tzanetakis, called \"gtzan\". This dataset contains 1.000 songs, 100 songs for 10 genres, and the task is therefore to predict the genres of a song; to limit file size, the songs are only 30 second snippets, and sampled with 22 khz only. You can download the dataset from the Moodle main page, or also at at http://kronos.ifs.tuwien.ac.at/GTZANmp3_22khz.zip. As this is copyrighted materials, please do not redistribute it...!\n",
    "\n",
    "As this is audio data, feature extraction is a requirement before we can actually learn anything. Therefore, there is demo code on how to work with this data available, linked from the course main page.\n",
    "\n",
    "This code generates different features, very simple ones containing just BeatsPerMinute, to more advanced ones based on advanced signal processing.  You shall work with all of them, and likely will see very different results.\n",
    "\n",
    "### Working in a group\n",
    "If you work in a group, as partially written above, your scope will be extended\n",
    "\n",
    "* More datasets: both music & image datasets\n",
    "* More parameter variations\n",
    "* More evaluation: for the Music&Image datasets, you shall also add an analysis of the confusion matrix for these datasets. It is sufficient, to provide one confusion matrix per feature set, you can select either the best classifier that you had on that feature set, or also other interesting ones.\n",
    "\n",
    "### Links for python\n",
    "* http://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html\n",
    "* http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html\n",
    "* http://scikit-learn.org/stable/modules/generated/sklearn.metrics.confusion_matrix.html\n",
    "\n",
    "### Non-python feature extractors\n",
    "#### Java\n",
    "* For images, you can use a port of openCV, the OpenCV bindings (http://docs.opencv.org/2.4/doc/tutorials/introduction/desktop_java/java_dev_intro.html) or a different implementation in  Java: https://github.com/bytedeco/javacv. The sample code should then be quite similar to the one in python.\n",
    "* For music: http://jmir.sourceforge.net/index_jAudio.html (the jAudio component) offers a GUI for extracting features, best is to use BPM (strongest beat), MFCCs and Chroma, and their derivatives, i.e. the statistics that are also used in the sample code. jAudio should be able to generate ARFF files for WEKA.\n",
    "\n",
    "#### C#\n",
    "* For image, you should find OpenCV bindings as well for C#\n",
    "\n",
    "## Sources used\n",
    "* Scikit documentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Solution\n",
    "\n",
    "### Helper Functions for Solution and Data Analysis"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# global Imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "#sk learn imports\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import make_scorer\n",
    "\n",
    "#Data reporting\n",
    "from IPython.display import display\n",
    "\n",
    "# Global definitions:\n",
    "overall_results_vote = []\n",
    "overall_results_amazon = []\n",
    "averaging_approach = 'macro'\n",
    "zero_division_approach = 0\n",
    "number_of_folds = 5\n",
    "scoring = {'Accuracy': make_scorer(accuracy_score),\n",
    "            'Precision': make_scorer(precision_score, average=averaging_approach, zero_division=zero_division_approach),\n",
    "            'Recall': make_scorer(recall_score, average=averaging_approach, zero_division=zero_division_approach)}\n",
    "\n",
    "# Helper functions\n",
    "def parse_k_fold_results(results):\n",
    "    return \"m: \" + str(np.average(results)) + \" std: \" + str(np.std(results))\n",
    "\n",
    "def parse_argument_tuple_as_string(argumentsTuple):\n",
    "    return \"max Depth: \" + str(argumentsTuple[0])  + \\\n",
    "           \", min Samples: \" + str(argumentsTuple[1])\n",
    "\n",
    "def calculate_results_holdout(classifier_used, X_train, X_test, y_train, y_test):\n",
    "    classifier_used.fit(X_train, y_train)\n",
    "\n",
    "    # predict the test set on our trained classifier\n",
    "    y_test_predicted = classifier_used.predict(X_test)\n",
    "\n",
    "    acc = metrics.accuracy_score(y_test, y_test_predicted)\n",
    "    recall=metrics.recall_score(y_test, y_test_predicted)\n",
    "    precision = metrics.precision_score(y_test, y_test_predicted)\n",
    "\n",
    "    return pd.Series({\n",
    "            'classifier': str(classifier_used),\n",
    "            'arguments': \"\",\n",
    "            'accuracy':acc,\n",
    "            'precision':precision,\n",
    "            'recall':recall\n",
    "        })\n",
    "\n",
    "def calculate_results_cross_validate(classifier_used, description_used, data, target):\n",
    "   scores = cross_validate(classifier_used, data, target,\n",
    "                                scoring = scoring,\n",
    "                                cv = number_of_folds,\n",
    "                                error_score = 0)\n",
    "\n",
    "   return pd.Series({\n",
    "            'classifier': str(classifier_used),\n",
    "            'arguments': description_used,\n",
    "            'mean_accuracy': np.average(scores.get('test_Accuracy')),\n",
    "            'mean_precision': np.average(scores.get('test_Precision')),\n",
    "            'mean_recall': np.average(scores.get('test_Recall')),\n",
    "            'accuracy': parse_k_fold_results(scores.get('test_Accuracy')),\n",
    "            'precision': parse_k_fold_results(scores.get('test_Precision')),\n",
    "            'recall':parse_k_fold_results(scores.get('test_Recall'))\n",
    "        })\n",
    "\n",
    "def print_results(array, column_for_max, ascending=False):\n",
    "    df = pd.DataFrame(array)\n",
    "    df = df.sort_values(by=[column_for_max], ascending=False)\n",
    "    display('Results', df)\n",
    "\n",
    "    best = df.iloc[df[column_for_max].argmax()]\n",
    "    display(best)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Calculation Functions\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### k-NN Calculation"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn import neighbors\n",
    "\n",
    "def calculate_knn(data, target):\n",
    "    knn_results = []\n",
    "\n",
    "    n_neighbors = range(1,10,1)\n",
    "\n",
    "    for n in n_neighbors:\n",
    "        knn_classifier = neighbors.KNeighborsClassifier(n)\n",
    "        description = \"N = \" + str(n)\n",
    "        result = calculate_results_cross_validate(knn_classifier,\n",
    "                                                  description,\n",
    "                                                  data,\n",
    "                                                  target)\n",
    "        knn_results.append(result)\n",
    "    return knn_results\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Bayes Calculation"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn import naive_bayes\n",
    "\n",
    "def calculate_bayes(data, target):\n",
    "    bayes_results = []\n",
    "\n",
    "    alphas = np.arange(0.1,5,1)\n",
    "\n",
    "    for alpha in alphas:\n",
    "        classifier = naive_bayes.CategoricalNB(alpha = alpha)\n",
    "        description = \"Alpha = \" + str(alpha)\n",
    "        result = calculate_results_cross_validate(classifier,\n",
    "                                                  description,\n",
    "                                                  data,\n",
    "                                                  target)\n",
    "        bayes_results.append(result)\n",
    "\n",
    "    return bayes_results"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Perceptron Calculation"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn import linear_model\n",
    "\n",
    "def calculate_perceptron(data, target):\n",
    "    perceptron_results=[]\n",
    "    classifier = linear_model.Perceptron()\n",
    "    description = \"No additional args.\"\n",
    "    result = calculate_results_cross_validate(classifier,\n",
    "                                              description,\n",
    "                                              data,\n",
    "                                              target)\n",
    "    perceptron_results.append(result)\n",
    "    return perceptron_results"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Decision Tree Calculation"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn import tree\n",
    "import itertools\n",
    "\n",
    "def calculate_decision_tree(data, target):\n",
    "    # Parameters for the decision tree\n",
    "    max_depth_arguments = range(1, 10, 2)\n",
    "    min_samples_leaf_arguments = [2,20,50,100]\n",
    "    argumentTuples = list(itertools.product(max_depth_arguments,\n",
    "                                            min_samples_leaf_arguments))\n",
    "    decision_tree_results = []\n",
    "\n",
    "    for argumentTuple in argumentTuples:\n",
    "        max_depth = argumentTuple[0]\n",
    "        min_samples_leaf = argumentTuple[1]\n",
    "\n",
    "        classifier = tree.DecisionTreeClassifier(criterion = 'gini',\n",
    "                                                 max_depth = max_depth,\n",
    "                                                 min_samples_leaf = min_samples_leaf,\n",
    "                                                 splitter = 'best')\n",
    "        #result = calculate_results_holdout(classifier, X_train, X_test, y_train, y_test)\n",
    "        result = calculate_results_cross_validate(classifier,\n",
    "                                                  parse_argument_tuple_as_string(argumentTuple),\n",
    "                                                  data,\n",
    "                                                  target)\n",
    "        decision_tree_results.append(result)\n",
    "    return decision_tree_results"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### SVM Calculation"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "import itertools\n",
    "\n",
    "def calculate_svm(data, target):\n",
    "    kernels = [\"poly\", \"rbf\"]#{\"linear\", \"poly\", \"sigmoid\", \"rbf\"}\n",
    "    gamma = [0.001, \"scale\", \"auto\"]\n",
    "    c = [100]\n",
    "    degree = range(1, 10, 1)\n",
    "\n",
    "    argumentTuples = list(itertools.product(kernels,\n",
    "                                            gamma,\n",
    "                                            c,\n",
    "                                            degree))\n",
    "    svm_results = []\n",
    "\n",
    "    for argumentTuple in argumentTuples:\n",
    "        kernel = argumentTuple[0]\n",
    "        gamma = argumentTuple[1]\n",
    "        c = argumentTuple[2]\n",
    "        degree = argumentTuple[3]\n",
    "\n",
    "        classifier = svm.SVC(kernel = kernel, gamma = gamma, C = c, degree = degree)\n",
    "\n",
    "        #result = calculate_results_holdout(classifier, X_train, X_test, y_train, y_test)\n",
    "        result = calculate_results_cross_validate(classifier,\n",
    "                                                  \"Kernel: \" + kernel + \", Degree: \" + str(degree),\n",
    "                                                  data,\n",
    "                                                  target)\n",
    "        svm_results.append(result)\n",
    "    return svm_results"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}